{"cells":[{"cell_type":"code","source":["spark"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["%fs ls /FileStore/tables/breast_cancer_wisconsin_data-e1a95.csv"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["%fs head /FileStore/tables/breast_cancer_wisconsin_data-e1a95.csv"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["%sql DROP TABLE IF EXISTS cancer"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["%sql\nCREATE TABLE cancer(\n  id INT,\n  diagnosis STRING,\n  radius_mean FLOAT,\n  texture_mean FLOAT,\n  perimeter_mean FLOAT,\n  area_mean FLOAT,\n  smoothness_mean FLOAT,\n  compactness_mean FLOAT,\n  concavity_mean FLOAT,\n  concave_points_mean FLOAT,\n  symmetry_mean FLOAT,\n  fractal_dimension_mean FLOAT,\n  radius_se FLOAT,\n  texture_se FLOAT,\n  perimeter_se FLOAT,\n  area_se FLOAT,\n  smoothness_se FLOAT,\n  compactness_se FLOAT, \n  concavity_se FLOAT,\n  concave_points_se FLOAT,\n  symmetry_se FLOAT,\n  fractal_dimension_se FLOAT,\n  radius_worst FLOAT,\n  texture_worst FLOAT,\n  perimeter_worst FLOAT,\n  area_worst FLOAT,\n  smoothness_worst FLOAT,\n  compactness_worst FLOAT,\n  concavity_worst FLOAT,\n  concave_points_worst FLOAT,\n  symmetry_worst FLOAT,\n  fractal_dimension_worst FLOAT)\nUSING com.databricks.spark.csv\nOPTIONS (path \"/FileStore/tables/breast_cancer_wisconsin_data-e1a95.csv\", header \"true\")"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["dataset=spark.table(\"cancer\")\ncols = dataset.columns"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["display(dataset)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\ncategoricalColumn = [\"diagnosis\"]\nstages = [] # stages in our Pipeline\nfor categoricalCol in categoricalColumn:\n  # Category Indexing with StringIndexer\n  stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\")\n  # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n  encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\")\n  # Add stages.  These are not run here, but will run all at once later on.\n  stages += [stringIndexer, encoder]"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# Convert label into label indices using the StringIndexer\nlabel_stringIdx = StringIndexer(inputCol = \"diagnosis\", outputCol = \"label\")\nstages += [label_stringIdx]"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# Transform all features into a vector using VectorAssembler\nnumericCols = [\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\"smoothness_mean\",\"compactness_mean\",\"concavity_mean\",\"concave_points_mean\",\"symmetry_mean\",\"fractal_dimension_mean\"]\nassemblerInputs = map(lambda c: c + \"classVec\", categoricalColumn) + numericCols\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n\nstages += [assembler]"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# Create a Pipeline.\npipeline = Pipeline(stages=stages)\n# Run the feature transformations.\n#  - fit() computes feature statistics as needed.\n#  - transform() actually transforms the features.\npipelineModel = pipeline.fit(dataset)\ndataset = pipelineModel.transform(dataset)\n\n# Keep relevant columns\nselectedcols = [\"label\", \"features\"] + cols\ndataset = dataset.select(selectedcols)\ndisplay(dataset)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["### Randomly split data into training and test sets. set seed for reproducibility\n(trainingData,testData)=dataset.randomSplit([0.7,0.3],seed=100)\nprint trainingData.count()\nprint testData.count()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["### Logistic Regression"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n\n# Create initial LogisticRegression model\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n\n# Train model with Training Data\nlrModel = lr.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# Make predictions on test data using the transform() method.\n# LogisticRegression.transform() will only use the 'features' column.\npredictions = lrModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# Make predictions on test data using the transform() method.\n# LogisticRegression.transform() will only use the 'features' column.\npredictions = lrModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["predictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["# View model's predictions and probabilities of each prediction class\n# You can select any columns in the above schema to view as well. For example's sake we will choose age & occupation\nselected = predictions.select(\"label\", \"prediction\", \"probability\", \"diagnosis\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["evaluator.getMetricName()"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["print lr.explainParams()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Create ParamGrid for Cross Validation\nparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n             .addGrid(lr.maxIter, [1, 5, 10])\n             .build())"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations\ncvModel = cv.fit(trainingData)\n# this will likely take a fair amount of time because of the amount of models that we're creating and testing"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["# Use test set here so we can measure the accuracy of our model on new data\npredictions = cvModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["print 'Model Intercept: ', cvModel.bestModel.interceptVector"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["#weights = cvModel.bestModel.weights\n# on Spark 2.X weights are available as ceofficients\nweights = cvModel.bestModel.coefficientMatrix\nweights = map(lambda w: (float(w),), weights)  # convert numpy type to float, and to tuple\nweightsDF = sqlContext.createDataFrame(weights, [\"Feature Weight\"])\ndisplay(weightsDF)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["# View best model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"prediction\", \"probability\", \"diagnosis\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["### Decision Tree"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import DecisionTreeClassifier\n\n# Create initial Decision Tree Model\ndt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=3)\n\n# Train model with Training Data\ndtModel = dt.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["print \"numNodes = \", dtModel.numNodes\nprint \"depth = \", dtModel.depth"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["# Make predictions on test data using the Transformer.transform() method.\npredictions = dtModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["predictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["# View model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"prediction\", \"probability\", \"diagnosis\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator()\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["dt.getImpurity()"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["# Create ParamGrid for Cross Validation\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(dt.maxDepth, [1,2,6,10])\n             .addGrid(dt.maxBins, [20,40,80])\n             .build())"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations\ncvModel = cv.fit(trainingData)\n# Takes ~5 minutes"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["print \"numNodes = \", cvModel.bestModel.numNodes\nprint \"depth = \", cvModel.bestModel.depth"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["# Use test set here so we can measure the accuracy of our model on new data\npredictions = cvModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["# View Best model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"prediction\", \"probability\", \"diagnosis\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":43}],"metadata":{"name":"Machine Learning on WDBC dataset","notebookId":1641097695598974},"nbformat":4,"nbformat_minor":0}
